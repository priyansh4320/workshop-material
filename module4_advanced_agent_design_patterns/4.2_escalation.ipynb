{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0adb9d1",
   "metadata": {},
   "source": [
    "# Advanced Agent Design Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a883bb",
   "metadata": {},
   "source": [
    "## Escalation\n",
    "\n",
    "The Escalation Pattern is a resource-efficient approach to task handling where simpler, less resource-intensive agents handle tasks first, with more capable (but potentially more expensive) agents only being engaged when necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade55178",
   "metadata": {},
   "source": [
    "![alt text](../images/escalation.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e1ce9",
   "metadata": {},
   "source": [
    "### Escalation Pattern Information Flow\n",
    "\n",
    "The Escalation Pattern is designed to maximize efficiency and ensure that each query receives the appropriate level of attention. The process is systematic, relying on structured confidence assessments at each stage to ensure consistent handling and optimal resource allocation.\n",
    "\n",
    "**Process Overview:**\n",
    "\n",
    "1. **Query Reception:**  \n",
    "   The triage agent receives the user query and routes it to the basic agent.\n",
    "\n",
    "2. **Confidence Assessment:**  \n",
    "   Each agent evaluates the query and provides a structured response along with a confidence score.\n",
    "\n",
    "3. **Escalation Decision:**  \n",
    "   - If the confidence score is **below the threshold** (typically < 8/10), the query is escalated to the next agent level.  \n",
    "   - If the confidence score is **above the threshold**, the response is returned to the user.\n",
    "\n",
    "4. **Context Tracking:**  \n",
    "   Context variables are used to track each agent's confidence score, the number of escalations, and the reasons for escalation.\n",
    "\n",
    "5. **Result Delivery:**  \n",
    "   The final answer is delivered to the user through the triage agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc236b",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "Implementing the Escalation Pattern requires thoughtful design of both the agent architecture and the communication protocol between agents. This approach uses structured data formats and explicit confidence reporting to ensure that escalation decisions are transparent and consistent. By leveraging a group chat orchestration engine, the pattern can be realized with minimal custom code, while still maintaining robust escalation logic and context preservation.\n",
    "\n",
    "**Key Implementation Elements:**\n",
    "\n",
    "- **Structured Response Format:**  \n",
    "  A Pydantic model (`ConsideredResponse`) is used to encapsulate the answer, confidence score, reasoning, and escalation information for each agent's response.\n",
    "\n",
    "- **Confidence Thresholds:**  \n",
    "  Agents escalate queries when their confidence falls below a defined threshold (e.g., 8/10).\n",
    "\n",
    "- **Agent-Specific Context Variables:**  \n",
    "  Each agent independently tracks its confidence and escalation decisions, allowing for granular context management.\n",
    "\n",
    "- **OnContextCondition:**  \n",
    "  Transitions between agents are triggered by evaluating context variables, ensuring that escalation only occurs when necessary.\n",
    "\n",
    "- **Tool Functions:**  \n",
    "  Specialized tool functions are employed to process structured responses and manage the escalation logic efficiently.\n",
    "\n",
    "This structured approach ensures that each query is handled at the appropriate level, optimizing both resource usage and response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7551b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example implementation of the Escalation Pattern for agent orchestration\n",
    "# with structured confidence outputs and agent-specific context variables\n",
    "\n",
    "import json\n",
    "from typing import Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from autogen import (\n",
    "    ConversableAgent,\n",
    "    UserProxyAgent,\n",
    "    ContextExpression,\n",
    "    LLMConfig,\n",
    ")\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group import ReplyResult, ContextVariables, AgentNameTarget, AgentTarget, RevertToUserTarget, OnContextCondition, StayTarget, ExpressionContextCondition, TerminateTarget\n",
    "from autogen.agentchat.group.patterns import DefaultPattern\n",
    "\n",
    "# Define structured output models\n",
    "class ConsideredResponse(BaseModel):\n",
    "    \"\"\"Structured response format for agents in the escalation pattern\"\"\"\n",
    "    answer: str = Field(..., description=\"The agent's answer to the query\")\n",
    "    confidence: int = Field(\n",
    "        ...,\n",
    "        description=\"Confidence level from 1-10 where 1 is extremely uncertain and 10 is absolutely certain\",\n",
    "    )\n",
    "    reasoning: str = Field(..., description=\"The agent's reasoning process\")\n",
    "    escalation_reason: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Reason for possible escalation if confidence < 8.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_question_asked(question: str, context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"If a new question is asked, this tool will reset context variables and route to the basic_agent. Only call this if the user has just asked a new question. If you have just received an answer, output it to the user.\"\"\"\n",
    "    context_variables[\"basic_agent_confidence\"] = 0\n",
    "    context_variables[\"intermediate_agent_confidence\"] = 0\n",
    "    context_variables[\"advanced_agent_confidence\"] = 0\n",
    "    context_variables[\"escalation_count\"] = 0\n",
    "    context_variables[\"last_escalation_reason\"] = \"\"\n",
    "    context_variables[\"last_escalating_agent\"] = \"\"\n",
    "\n",
    "    context_variables[\"current_question\"] = question\n",
    "    return ReplyResult(\n",
    "        target=AgentNameTarget(\"basic_agent\"),\n",
    "        context_variables=context_variables,\n",
    "        message=f\"New question received, context variables reset.\\n\\nbasic_agent try and answer this question:\\n{question}\"\n",
    "    )\n",
    "\n",
    "def answer_question_common(response: ConsideredResponse, agent_level: str, context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Common question answer function that updates context variables and routes based on the answer confidence.\n",
    "\n",
    "    agent_level will be one of \"basic\", \"intermediate\", or \"advanced\".\n",
    "    \"\"\"\n",
    "    context_variables[f\"{agent_level}_agent_confidence\"] = response.confidence\n",
    "\n",
    "    if response.confidence < 8:\n",
    "        context_variables[\"escalation_count\"] = context_variables[\"escalation_count\"] + 1\n",
    "        context_variables[\"last_escalation_reason\"] = response.escalation_reason\n",
    "        context_variables[\"last_escalating_agent\"] = f\"{agent_level}_agent\"\n",
    "\n",
    "        if agent_level == \"advanced\":\n",
    "            return ReplyResult(target=AgentNameTarget(\"triage_agent\"), context_variables=context_variables, message=f\"I am not confident with my answer (confidence level {response.confidence}/10, reason:\\n{response.escalation_reason}\\n\\nanswer: {response.answer}\\n\\nPlease consult a human expert.\")\n",
    "\n",
    "        next_agent_level = \"intermediate\" if agent_level == \"basic\" else \"advanced\"\n",
    "        return ReplyResult(target=AgentNameTarget(f\"{next_agent_level}_agent\"), context_variables=context_variables, message=f\"Need to escalate with confidence {response.confidence}/10, reason:\\n{response.escalation_reason}\")\n",
    "    else:\n",
    "        return ReplyResult(target=AgentNameTarget(\"triage_agent\"), context_variables=context_variables, message=f\"Successfully answered with confidence ({response.confidence}/10):\\n{response.answer}\")\n",
    "\n",
    "def answer_question_basic(response: ConsideredResponse, context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Always call this tool with your answer.\"\"\"\n",
    "    return answer_question_common(response, \"basic\", context_variables)\n",
    "\n",
    "def answer_question_intermediate(response: ConsideredResponse, context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Always call this tool with your answer.\"\"\"\n",
    "    return answer_question_common(response, \"intermediate\", context_variables)\n",
    "\n",
    "def answer_question_advanced(response: ConsideredResponse, context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Always call this tool with your answer.\"\"\"\n",
    "    return answer_question_common(response, \"advanced\", context_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89462be",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_agent = ConversableAgent(\n",
    "        name=\"triage_agent\",\n",
    "        system_message=\"\"\"You are a triage agent that routes queries to the appropriate level of expertise.\n",
    "        If there's a new question, call the new_question_asked tool to process it.\n",
    "        If a question has been successfully answered, output the question and answer and don't call a tool.\n",
    "        You should never answer the question yourself.\n",
    "        \"\"\",\n",
    "        functions=[new_question_asked],\n",
    "        llm_config=LLMConfig(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            temperature=0,\n",
    "            cache_seed=None,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create agents of increasing capability/cost\n",
    "basic_agent = ConversableAgent(\n",
    "    name=\"basic_agent\",\n",
    "    system_message=\"\"\"You are a basic agent that handles simple tasks efficiently.\n",
    "    You can answer common knowledge questions and perform basic calculations.\n",
    "    You MUST provide your responses in the required structured format, including a confidence score from 1-10.\n",
    "    If a query requires specialized knowledge beyond your capabilities or is complex, set needs_escalation to True\n",
    "    and provide a brief reason in escalation_reason.\n",
    "    Confidence level guide:\n",
    "    - 1-3: Very uncertain, likely to be incorrect\n",
    "    - 4-6: Moderate confidence, might be correct\n",
    "    - 7-8: Good confidence, probably correct\n",
    "    - 9-10: High confidence, almost certainly correct\n",
    "    For simple factual questions and basic calculations that you can handle well, your confidence should be 8-10.\n",
    "    For it's not a simple question, rate accordingly lower.\n",
    "    Always call the answer_question_basic tool when answering.\n",
    "    \"\"\",\n",
    "    functions=[answer_question_basic],\n",
    "    llm_config=LLMConfig(\n",
    "        api_type=\"openai\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        cache_seed=None,\n",
    "    )\n",
    ")\n",
    "intermediate_agent = ConversableAgent(\n",
    "    name=\"intermediate_agent\",\n",
    "    system_message=\"\"\"You are an intermediate agent that handles moderately complex tasks.\n",
    "    You can perform more nuanced analysis, provide detailed explanations, and handle domain-specific knowledge.\n",
    "    You MUST provide your responses in the required structured format, including a confidence score from 1-10.\n",
    "    If a query requires deep expertise or is very complex beyond your capabilities, set needs_escalation to True\n",
    "    and provide a brief reason in escalation_reason.\n",
    "    Confidence level guide:\n",
    "    - 1-3: Very uncertain, likely to be incorrect\n",
    "    - 4-6: Moderate confidence, might be correct\n",
    "    - 7-8: Good confidence, probably correct\n",
    "    - 9-10: High confidence, almost certainly correct\n",
    "    For questions within your knowledge domain that you can handle well, your confidence should be 8-10.\n",
    "    For more specialized or complex questions where you're less certain, rate accordingly lower.\n",
    "    \"\"\",\n",
    "    functions=[answer_question_intermediate],\n",
    "    llm_config=LLMConfig(\n",
    "        api_type=\"openai\",\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        seed=42,\n",
    "    )\n",
    ")\n",
    "advanced_agent = ConversableAgent(\n",
    "    name=\"advanced_agent\",\n",
    "    system_message=\"\"\"You are an advanced agent with extensive knowledge and reasoning capabilities.\n",
    "    You can handle complex reasoning, specialized domains, and difficult problem-solving tasks.\n",
    "    You MUST provide your responses in the required structured format, including a confidence score from 1-10.\n",
    "    If a task is beyond even your capabilities, set needs_escalation to True and recommend consulting a human expert\n",
    "    in the escalation_reason field.\n",
    "    Confidence level guide:\n",
    "    - 1-3: Very uncertain, likely to be incorrect\n",
    "    - 4-6: Moderate confidence, might be correct\n",
    "    - 7-8: Good confidence, probably correct\n",
    "    - 9-10: High confidence, almost certainly correct\n",
    "    For questions that you can handle well, your confidence should be 8-10.\n",
    "    For extremely specialized or cutting-edge questions where you're less certain, rate accordingly lower.\n",
    "    \"\"\",\n",
    "    functions=[answer_question_advanced],\n",
    "    llm_config=LLMConfig(\n",
    "        api_type=\"anthropic\",\n",
    "        model=\"claude-3-7-sonnet-20250219\",\n",
    "        seed=42,\n",
    "    )\n",
    ")\n",
    "# Create a user proxy agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    system_message=\"You are a proxy for the human user.\",\n",
    "    human_input_mode=\"ALWAYS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_agent.handoffs.add_context_condition(\n",
    "        OnContextCondition(\n",
    "            target=AgentTarget(advanced_agent),\n",
    "            condition=ExpressionContextCondition(expression=ContextExpression(\"${intermediate_agent_confidence} > 0 and ${intermediate_agent_confidence} < 8\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Advanced agent falls back to user when all agents are insufficient\n",
    "advanced_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "# Initial context variables with agent-specific confidence and escalation flags\n",
    "context_variables = ContextVariables(data={\n",
    "    # Agent-specific variables\n",
    "    \"basic_agent_confidence\": 0,\n",
    "    \"intermediate_agent_confidence\": 0,\n",
    "    \"advanced_agent_confidence\": 0,\n",
    "    # Global tracking variables\n",
    "    \"escalation_count\": 0,\n",
    "    \"last_escalation_reason\": \"\",\n",
    "    \"last_escalating_agent\": \"\",\n",
    "    \"current_question\": \"\"\n",
    "})\n",
    "basic_question = \"What is 100 divided by 5?\"\n",
    "intermediate_question = (\n",
    "    \"Calculate the energy of a quantum system with three particles in a harmonic oscillator potential. \"\n",
    "    \"The first particle has energy level n=2, the second particle has energy level n=1, and the third particle has energy level n=0. \"\n",
    "    \"Assume the harmonic oscillator has a frequency of ω = 2.5 eV/ħ.\"\n",
    "    )\n",
    "advanced_question = (\n",
    "    \"Develop a mathematical model for optimizing the tradeoff between exploration and exploitation in reinforcement learning for a \"\n",
    "    \"non-stationary multi-armed bandit problem where the reward distributions shift according to a hidden Markov model. \"\n",
    "    \"Include the formal equations for the Upper Confidence Bound (UCB) algorithm modification you would propose, and explain \"\n",
    "    \"how your approach addresses the non-stationarity challenge better than Thompson Sampling with a sliding window.\"\n",
    "    )\n",
    "agent_pattern = DefaultPattern(\n",
    "    agents=[\n",
    "        basic_agent,\n",
    "        intermediate_agent,\n",
    "        advanced_agent,\n",
    "        triage_agent\n",
    "    ],\n",
    "    initial_agent=triage_agent,\n",
    "    context_variables=context_variables,\n",
    "    group_after_work=TerminateTarget(),\n",
    "    user_agent=user_proxy,\n",
    ")\n",
    "chat_result, final_context, last_speaker = initiate_group_chat(\n",
    "    pattern=agent_pattern,\n",
    "    messages=advanced_question, # Try different questions\n",
    "    max_rounds=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== SUMMARY =====\\n\")\n",
    "print(chat_result.summary)\n",
    "print(\"\\n\\n===== FINAL CONTEXT VARIABLES =====\\n\")\n",
    "print(json.dumps(final_context.to_dict(), indent=2))\n",
    "print(\"\\n\\n===== SPEAKER ORDER =====\\n\")\n",
    "for message in chat_result.chat_history:\n",
    "    if \"name\" in message and message[\"name\"] != \"_Group_Tool_Executor\":\n",
    "        print(f\"{message['name']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
