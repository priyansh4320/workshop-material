{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1d2925",
   "metadata": {},
   "source": [
    "# Installing and Getting Started with Ag2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78875ef",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "AG2 is available on [PyPI](https://pypi.org/project/ag2/) and can be installed using `pip`, the Python package manager.\n",
    "\n",
    "**Basic installation (with OpenAI support):**\n",
    "\n",
    "```bash\n",
    "pip install \"ag2[openai]\"\n",
    "```\n",
    "\n",
    "**Install with additional model providers:**\n",
    "\n",
    "```bash\n",
    "pip install \"ag2[anthropic,cohere,mistral,gemini]\"\n",
    "```\n",
    "\n",
    "You can specify any combination of providers in the brackets, depending on your needs.\n",
    "\n",
    "> **Tip:** We recommend using a [virtual environment](https://docs.python.org/3/tutorial/venv.html) (such as `venv` or `conda`) for your project to keep dependencies isolated and manageable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69843d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"ag2[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf5836",
   "metadata": {},
   "source": [
    "## Basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d97d34",
   "metadata": {},
   "source": [
    " ### LLM Configuration\n",
    " \n",
    " The **LLM Configuration** specifies the language model intelligence that powers your agents. It is the first component you should set up when building with AG2, as it determines how your agents will think, reason, and generate responses.\n",
    " \n",
    " The LLM Configuration allows you to:\n",
    " \n",
    " - **Connect to and authenticate** with language model providers\n",
    " - **Select models** and adjust their parameters\n",
    " - **Control how your agent thinks, reasons, and responds**\n",
    " \n",
    " Properly configuring your LLM ensures your agents have the right capabilities for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11796ec",
   "metadata": {},
   "source": [
    "creating and LLM Configuration\n",
    "we have 2 methods \n",
    "1) Using Direct Parameters\n",
    "2) Using the config_list Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a54d3f",
   "metadata": {},
   "source": [
    "Method 1: Using Direct Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",                      # The provider\n",
    "    model=\"gpt-5-nano\",                    # The specific model\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],   # Authentication\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2371e7",
   "metadata": {},
   "source": [
    "Method 2: Using the config_list Parameter\n",
    "- For more advanced scenarios, especially when you want to set up fallback models, use the config_list parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list=[\n",
    "        {\n",
    "            \"api_type\": \"openai\",\n",
    "            \"model\": \"gpt-5-nano\",\n",
    "            \"api_key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "        },\n",
    "        {\n",
    "            \"api_type\": \"openai\",\n",
    "            \"model\": \"o3-mini\",\n",
    "            \"api_key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac8515",
   "metadata": {},
   "source": [
    "### ConversableAgent\n",
    "\n",
    "The ConversableAgent is the core building block of AG2 ‚Äî a smart, interactive agent that uses your configured LLM to process information and interact with other agents or humans. With a properly configured LLM, your agents can:\n",
    "\n",
    "- Communicate with other agents and humans\n",
    "- Process information using Large Language Models (LLMs)\n",
    "- Make decisions based on its defined purpose\n",
    "- Execute tools and functions when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ae9db",
   "metadata": {},
   "source": [
    "Every agent in your AG2 system is either a ConversableAgent or built upon one, making it the most important class to understand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab7a07",
   "metadata": {},
   "source": [
    " ## Creating a `ConversableAgent`\n",
    "\n",
    " The `ConversableAgent` is the fundamental building block for building intelligent, interactive agents in AG2.\n",
    "\n",
    " **Key Parameters:**\n",
    "\n",
    " When initializing a `ConversableAgent`, consider the following important parameters:\n",
    "\n",
    " - **`name`**:  \n",
    "   A unique identifier for your agent. This helps distinguish between multiple agents in your system.\n",
    "\n",
    " - **`system_message`**:  \n",
    "   Instructions that define the agent's role, personality, and behavior. This message guides how the agent responds and interacts.\n",
    "\n",
    " - **`llm_config`**:  \n",
    "   Configuration for the language model. This can be provided directly or via a context manager, and determines which LLM the agent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b325bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# Create LLM configuration first\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create the agent using the context manager approach\n",
    "my_agent = ConversableAgent(\n",
    "    name=\"helpful_agent\",  # Give your agent a unique name\n",
    "    system_message=\"You are a helpful AI assistant\",  # Define its personality and purpose\n",
    "    llm_config=llm_config  # Pass the LLM configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78636d",
   "metadata": {},
   "source": [
    "**Interacting with a ConversableAgent**\n",
    "- The simplest way to interact with a ConversableAgent is to use the run() and process() methods. Here's a basic example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793c7e3",
   "metadata": {},
   "source": [
    " ### Why Two Steps? `run()` and `process()`\n",
    " \n",
    " When you call `run()`, it does **not** immediately return the final output. Instead, it gives you an **iterator**‚Äîa special object that streams events, messages, and metadata as the conversation unfolds.\n",
    " \n",
    " The `process()` method is a convenient helper that automatically iterates through these events for you. It simulates a chat-like console experience: printing messages, handling user input, and making the interaction feel live and conversational.\n",
    " \n",
    " **Summary:**\n",
    " \n",
    " - Use **`run()`** and manually iterate over the events if you want **full control** over the workflow and how each event is handled.\n",
    " - Use **`process()`** (typically in combination with `run()`) for a **quick, ready-to-use chat experience** in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the workflow\n",
    "response = my_agent.run(\n",
    "    message=\"What's the capital of France?\",\n",
    "    max_turns=2,  # Limit conversation length\n",
    "    user_input=True  # Allow user to provide input\n",
    ")\n",
    "\n",
    "# Process the workflow\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8be05a",
   "metadata": {},
   "source": [
    "### üè¶ Financial Compliance Example\n",
    "\n",
    "Let's build a simple **financial agent** using `ConversableAgent` to help analyze transactions and discuss compliance topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964949be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "import os\n",
    "\n",
    "# Configure the LLM (we created this in the previous section)\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Create a basic financial agent\n",
    "with llm_config:\n",
    "    finance_agent = ConversableAgent(\n",
    "        name=\"finance_agent\",\n",
    "        system_message=\"You are a financial assistant who helps analyze financial data and transactions.\"\n",
    "    )\n",
    "\n",
    "# Run the agent with a prompt\n",
    "response = finance_agent.run(\n",
    "    message=\"Can you explain what makes a transaction suspicious?\",\n",
    "    max_turns=1\n",
    ")\n",
    "\n",
    "# Iterate through the chat automatically with console output\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876af157",
   "metadata": {},
   "source": [
    "### Human in the Loop\n",
    "\n",
    "Human in the Loop (HITL) is a powerful pattern that enables your AG2 agents to collaborate with humans during their workflow. Instead of making all decisions independently, agents can check with human operators at critical decision points, combining AI efficiency with human judgment.\n",
    "\n",
    "\n",
    "- Enables human approval before proceeding in a workflow\n",
    "- Integrates feedback into the decision-making process\n",
    "- Balances automation with human judgment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c350a9",
   "metadata": {},
   "source": [
    " ## üïµÔ∏è‚Äç‚ôÇÔ∏è When Should You Use Human in the Loop (HITL)?\n",
    "\n",
    " Human in the Loop (HITL) is especially important in scenarios where:\n",
    "\n",
    " - **Nuanced judgment is required:**  \n",
    "   For example, in financial compliance or legal matters where context and expertise are crucial.\n",
    " - **Mistakes could have serious consequences:**  \n",
    "   Such as in financial transactions or safety-critical systems, where errors can be costly or dangerous.\n",
    " - **Subjective input improves outcomes:**  \n",
    "   Like content approval or design choices, where human taste and preferences matter.\n",
    " - **Regulations require human oversight:**  \n",
    "   In industries such as financial services or healthcare, where laws mandate a human review step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b105e",
   "metadata": {},
   "source": [
    "```\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# Create a human agent that will always prompt for input\n",
    "human = ConversableAgent(\n",
    "    name=\"human\",\n",
    "    human_input_mode=\"ALWAYS\",  # Always ask for human input\n",
    ")\n",
    "\n",
    "# Create an AI agent that never asks for human input directly\n",
    "ai_agent = ConversableAgent(\n",
    "    name=\"ai_assistant\",\n",
    "    system_message=\"You are a helpful AI assistant\",\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input directly\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133df18c",
   "metadata": {},
   "source": [
    "The human_input_mode parameter has three possible values:\n",
    "\n",
    "1) ALWAYS: The agent uses the human input as its response\n",
    "2) TERMINATE: The agent asks for input only when terminating a conversation\n",
    "3) NEVER: The agent never asks for human input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b8c86",
   "metadata": {},
   "source": [
    "**let's continue the financial complience example with (HITL)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Note: Make sure to set your API key in your environment first\n",
    "\n",
    "# Configure the LLM\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Define the system message for our finance bot\n",
    "finance_system_message = \"\"\"\n",
    "You are a financial compliance assistant. You will be given a set of transaction descriptions.\n",
    "For each transaction:\n",
    "- If it seems suspicious (e.g., amount > $10,000, vendor is unusual, memo is vague), ask the human agent for approval.\n",
    "- Otherwise, approve it automatically.\n",
    "Provide the full set of transactions to approve at one time.\n",
    "If the human gives a general approval, it applies to all transactions requiring approval.\n",
    "When all transactions are processed, summarize the results and say \"You can type exit to finish\".\n",
    "\"\"\"\n",
    "\n",
    "# Create the finance agent with LLM intelligence\n",
    "with llm_config:\n",
    "    finance_bot = ConversableAgent(\n",
    "        name=\"finance_bot\",\n",
    "        system_message=finance_system_message,\n",
    "    )\n",
    "\n",
    "# Create the human agent for oversight\n",
    "human = ConversableAgent(\n",
    "    name=\"human\",\n",
    "    human_input_mode=\"ALWAYS\",  # Always ask for human input\n",
    ")\n",
    "\n",
    "# Generate sample transactions - this creates different transactions each time you run\n",
    "VENDORS = [\"Staples\", \"Acme Corp\", \"CyberSins Ltd\", \"Initech\", \"Globex\", \"Unicorn LLC\"]\n",
    "MEMOS = [\"Quarterly supplies\", \"Confidential\", \"NDA services\", \"Routine payment\", \"Urgent request\", \"Reimbursement\"]\n",
    "\n",
    "def generate_transaction():\n",
    "    amount = random.choice([500, 1500, 9999, 12000, 23000, 4000])\n",
    "    vendor = random.choice(VENDORS)\n",
    "    memo = random.choice(MEMOS)\n",
    "    return f\"Transaction: ${amount} to {vendor}. Memo: {memo}.\"\n",
    "\n",
    "# Generate 3 random transactions\n",
    "transactions = [generate_transaction() for _ in range(3)]\n",
    "\n",
    "# Format the initial message\n",
    "initial_prompt = (\n",
    "    \"Please process the following transactions one at a time:\\n\\n\" +\n",
    "    \"\\n\".join([f\"{i+1}. {tx}\" for i, tx in enumerate(transactions)])\n",
    ")\n",
    "\n",
    "# Start the conversation from the human agent\n",
    "response = human.run(\n",
    "    recipient=finance_bot,\n",
    "    message=initial_prompt,\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97721cd6",
   "metadata": {},
   "source": [
    "### Agent Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2514b26",
   "metadata": {},
   "source": [
    "Agent Orchestration defines patterns for coordinating multiple agents, allowing them to work together in various configurations:\n",
    "\n",
    "- Two-agent conversations\n",
    "- Sequential conversations that chain multiple dialogues\n",
    "- Group collaborations with many agents\n",
    "- Nested workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b3902",
   "metadata": {},
   "source": [
    "AG2 offers several orchestration patterns, and for our evolving Agentic system, the Group Chat pattern is particularly powerful. It allows specialized agents to collaborate with dynamic handoffs to achieve complex workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d2c19",
   "metadata": {},
   "source": [
    "Here's how you implement a basic group chat:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "\n",
    "# Create your specialized agents\n",
    "with llm_config:\n",
    "    agent_1 = ConversableAgent(name=\"agent_1\", system_message=\"...\")\n",
    "    agent_2 = ConversableAgent(name=\"agent_2\", system_message=\"...\")\n",
    "\n",
    "# Create human agent if needed\n",
    "human = ConversableAgent(name=\"human\", human_input_mode=\"ALWAYS\")\n",
    "\n",
    "# Set up the pattern for orchestration\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=agent_1,              # Agent that starts the workflow\n",
    "    agents=[agent_1, agent_2],          # All agents in the group chat\n",
    "    user_agent=human,                   # Human agent for interaction\n",
    "    group_manager_args={\"llm_config\": llm_config}  # Config for group manager\n",
    ")\n",
    "\n",
    "# Initialize the group chat\n",
    "result, context_variables, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"Initial request\",         # Starting message\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689c948",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d8176",
   "metadata": {},
   "source": [
    "The tools extend an agent‚Äôs capabilities beyond text conversations, enabling them to:\n",
    "\n",
    "- Connect with external APIs and services\n",
    "- Perform calculations and data processing\n",
    "- Access and work with files, databases, or other systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b687f8",
   "metadata": {},
   "source": [
    "### how tool works\n",
    "- Selection: An agent (driven by its LLM) decides which tool is appropriate based on the given task\n",
    "- Execution: A separate executor agent invokes the tool and returns the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eed209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Annotated, Any\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "\n",
    "# Note: Make sure to set your API key in your environment first\n",
    "\n",
    "# Configure the LLM\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Mock database of previous transactions\n",
    "def get_previous_transactions() -> list[dict[str, Any]]:\n",
    "    today = datetime.now()\n",
    "    return [\n",
    "        {\n",
    "            \"vendor\": \"Staples\",\n",
    "            \"amount\": 500,\n",
    "            \"date\": (today - timedelta(days=3)).strftime(\"%Y-%m-%d\"),  # 3 days ago\n",
    "            \"memo\": \"Quarterly supplies\",\n",
    "        },\n",
    "        {\n",
    "            \"vendor\": \"Acme Corp\",\n",
    "            \"amount\": 1500,\n",
    "            \"date\": (today - timedelta(days=10)).strftime(\"%Y-%m-%d\"),  # 10 days ago\n",
    "            \"memo\": \"NDA services\",\n",
    "        },\n",
    "        {\n",
    "            \"vendor\": \"Globex\",\n",
    "            \"amount\": 12000,\n",
    "            \"date\": (today - timedelta(days=5)).strftime(\"%Y-%m-%d\"),  # 5 days ago\n",
    "            \"memo\": \"Confidential\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Simple duplicate detection function\n",
    "def check_duplicate_payment(\n",
    "    vendor: Annotated[str, \"The vendor name\"],\n",
    "    amount: Annotated[float, \"The transaction amount\"],\n",
    "    memo: Annotated[str, \"The transaction memo\"]\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Check if a transaction appears to be a duplicate of a recent payment\"\"\"\n",
    "    previous_transactions = get_previous_transactions()\n",
    "\n",
    "    today = datetime.now()\n",
    "\n",
    "    for tx in previous_transactions:\n",
    "        tx_date = datetime.strptime(tx[\"date\"], \"%Y-%m-%d\")\n",
    "        date_diff = (today - tx_date).days\n",
    "\n",
    "        # If vendor, memo and amount match, and transaction is within 7 days\n",
    "        if (\n",
    "            tx[\"vendor\"] == vendor and\n",
    "            tx[\"memo\"] == memo and\n",
    "            tx[\"amount\"] == amount and\n",
    "            date_diff <= 7\n",
    "        ):\n",
    "            return {\n",
    "                \"is_duplicate\": True,\n",
    "                \"reason\": f\"Duplicate payment to {vendor} for ${amount} on {tx['date']}\"\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        \"is_duplicate\": False,\n",
    "        \"reason\": \"No recent duplicates found\"\n",
    "    }\n",
    "\n",
    "# Define the system message for our finance bot\n",
    "finance_system_message = \"\"\"\n",
    "You are a financial compliance assistant. You will be given a set of transaction descriptions.\n",
    "\n",
    "For each transaction:\n",
    "1. First, extract the vendor name, amount, and memo\n",
    "2. Check if the transaction is a duplicate using the check_duplicate_payment tool\n",
    "3. If the tool identifies a duplicate, automatically reject the transaction\n",
    "4. If not a duplicate, continue with normal evaluation:\n",
    "    - If it seems suspicious (e.g., amount > $10,000, vendor is unusual, memo is vague), ask the human agent for approval\n",
    "    - Otherwise, approve it automatically\n",
    "\n",
    "Provide clear explanations for your decisions, especially for duplicates or suspicious transactions.\n",
    "When all transactions are processed, summarize the results and say \"You can type exit to finish\".\n",
    "\"\"\"\n",
    "\n",
    "# Define the system message for the summary agent\n",
    "summary_system_message = \"\"\"\n",
    "You are a financial summary assistant. You will be given a set of transaction details and their approval status.\n",
    "Your task is to summarize the results of the transactions processed by the finance bot.\n",
    "Generate a markdown table with the following columns:\n",
    "- Vendor\n",
    "- Memo\n",
    "- Amount\n",
    "- Status (Approved/Rejected)\n",
    "- Reason (especially note if rejected due to being a duplicate)\n",
    "\n",
    "The summary should include the total number of transactions, the number of approved transactions, and the number of rejected transactions.\n",
    "The summary should be concise and clear.\n",
    "\n",
    "Once you've generated the summary append the below in the summary:\n",
    "==== SUMMARY GENERATED ====\n",
    "\"\"\"\n",
    "\n",
    "# Create the finance agent with LLM intelligence\n",
    "with llm_config:\n",
    "    finance_bot = ConversableAgent(\n",
    "        name=\"finance_bot\",\n",
    "        system_message=finance_system_message,\n",
    "        functions=[check_duplicate_payment],\n",
    "    )\n",
    "    summary_bot = ConversableAgent(\n",
    "        name=\"summary_bot\",\n",
    "        system_message=summary_system_message,\n",
    "    )\n",
    "\n",
    "# Create the human agent for oversight\n",
    "human = ConversableAgent(\n",
    "    name=\"human\",\n",
    "    human_input_mode=\"ALWAYS\",  # Always ask for human input\n",
    ")\n",
    "\n",
    "def is_termination_msg(msg: dict[str, Any]) -> bool:\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    return (content is not None) and \"==== SUMMARY GENERATED ====\" in content\n",
    "\n",
    "# Generate sample transactions - this creates different transactions each time you run\n",
    "VENDORS = [\"Staples\", \"Acme Corp\", \"CyberSins Ltd\", \"Initech\", \"Globex\", \"Unicorn LLC\"]\n",
    "MEMOS = [\"Quarterly supplies\", \"Confidential\", \"NDA services\", \"Routine payment\", \"Urgent request\", \"Reimbursement\"]\n",
    "\n",
    "# Generate new transactions including a duplicate\n",
    "transactions = [\n",
    "    \"Transaction: $500 to Staples. Memo: Quarterly supplies.\",  # Duplicate of an existing transaction\n",
    "    \"Transaction: $4000 to Unicorn LLC. Memo: Reimbursement.\",\n",
    "    \"Transaction: $12000 to Globex. Memo: Confidential.\",  # Duplicate of an existing transaction\n",
    "    \"Transaction: $22000 to Initech. Memo: Urgent request.\"\n",
    "]\n",
    "\n",
    "# Format the initial message\n",
    "initial_prompt = (\n",
    "    \"Please process the following transactions one at a time, checking for duplicates:\\n\\n\" +\n",
    "    \"\\n\".join([f\"{i+1}. {tx}\" for i, tx in enumerate(transactions)])\n",
    ")\n",
    "\n",
    "# Create pattern and start group chat\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=finance_bot,\n",
    "    agents=[finance_bot, summary_bot],\n",
    "    user_agent=human,\n",
    "    group_manager_args = {\n",
    "        \"llm_config\": llm_config,\n",
    "        \"is_termination_msg\": is_termination_msg\n",
    "    },\n",
    ")\n",
    "\n",
    "result, _, _ = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=initial_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde10b5e",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288e435",
   "metadata": {},
   "source": [
    "Structured Outputs ensure agents return well-defined, consistent, and validated responses using Pydantic models. This allows you to:\n",
    "\n",
    "- Define structured response formats\n",
    "- Guarantee consistent data structures\n",
    "- Simplify downstream processing and application integration\n",
    "- Ensure responses are complete and reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b380e03",
   "metadata": {},
   "source": [
    "**Implementing structured outputs in AG2 is straightforward using Pydantic models and the response_format parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30485a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# 1. Define your structured output model with Pydantic\n",
    "class ResponseModel(BaseModel):\n",
    "    field1: str\n",
    "    field2: int\n",
    "    field3: list[str]\n",
    "\n",
    "# 2. Create LLM configuration with the structured output model\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=ResponseModel,  # Specify the response format\n",
    ")\n",
    "\n",
    "# 3. Create agent with structured output configuration\n",
    "with llm_config:\n",
    "    structured_agent = ConversableAgent(\n",
    "        name=\"structured_agent\",\n",
    "        system_message=\"You provide information in a structured format.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
