{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1d2925",
   "metadata": {},
   "source": [
    "# Installing and Getting Started with Ag2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78875ef",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "AG2 is available on [PyPI](https://pypi.org/project/ag2/) and can be installed using `pip`, the Python package manager.\n",
    "\n",
    "**Basic installation (with OpenAI support):**\n",
    "\n",
    "```bash\n",
    "pip install \"ag2[openai]\"\n",
    "```\n",
    "\n",
    "**Install with additional model providers:**\n",
    "\n",
    "```bash\n",
    "pip install \"ag2[anthropic,cohere,mistral,gemini]\"\n",
    "```\n",
    "\n",
    "You can specify any combination of providers in the brackets, depending on your needs.\n",
    "\n",
    "> **Tip:** We recommend using a [virtual environment](https://docs.python.org/3/tutorial/venv.html) (such as `venv` or `conda`) for your project to keep dependencies isolated and manageable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69843d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"ag2[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf5836",
   "metadata": {},
   "source": [
    "## Basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d97d34",
   "metadata": {},
   "source": [
    " ### LLM Configuration\n",
    " \n",
    " The **LLM Configuration** specifies the language model intelligence that powers your agents. It is the first component you should set up when building with AG2, as it determines how your agents will think, reason, and generate responses.\n",
    " \n",
    " The LLM Configuration allows you to:\n",
    " \n",
    " - **Connect to and authenticate** with language model providers\n",
    " - **Select models** and adjust their parameters\n",
    " - **Control how your agent thinks, reasons, and responds**\n",
    " \n",
    " Properly configuring your LLM ensures your agents have the right capabilities for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11796ec",
   "metadata": {},
   "source": [
    "creating and LLM Configuration\n",
    "we have 2 methods \n",
    "1) Using Direct Parameters\n",
    "2) Using the config_list Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a54d3f",
   "metadata": {},
   "source": [
    "Method 1: Using Direct Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",                      # The provider\n",
    "    model=\"gpt-5-nano\",                    # The specific model\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],   # Authentication\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2371e7",
   "metadata": {},
   "source": [
    "Method 2: Using the config_list Parameter\n",
    "- For more advanced scenarios, especially when you want to set up fallback models, use the config_list parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list=[\n",
    "        {\n",
    "            \"api_type\": \"openai\",\n",
    "            \"model\": \"gpt-5-nano\",\n",
    "            \"api_key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "        },\n",
    "        {\n",
    "            \"api_type\": \"openai\",\n",
    "            \"model\": \"o3-mini\",\n",
    "            \"api_key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac8515",
   "metadata": {},
   "source": [
    "### ConversableAgent\n",
    "\n",
    "The ConversableAgent is the core building block of AG2 ‚Äî a smart, interactive agent that uses your configured LLM to process information and interact with other agents or humans. With a properly configured LLM, your agents can:\n",
    "\n",
    "- Communicate with other agents and humans\n",
    "- Process information using Large Language Models (LLMs)\n",
    "- Make decisions based on its defined purpose\n",
    "- Execute tools and functions when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ae9db",
   "metadata": {},
   "source": [
    "Every agent in your AG2 system is either a ConversableAgent or built upon one, making it the most important class to understand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab7a07",
   "metadata": {},
   "source": [
    " ## Creating a `ConversableAgent`\n",
    "\n",
    " The `ConversableAgent` is the fundamental building block for building intelligent, interactive agents in AG2.\n",
    "\n",
    " **Key Parameters:**\n",
    "\n",
    " When initializing a `ConversableAgent`, consider the following important parameters:\n",
    "\n",
    " - **`name`**:  \n",
    "   A unique identifier for your agent. This helps distinguish between multiple agents in your system.\n",
    "\n",
    " - **`system_message`**:  \n",
    "   Instructions that define the agent's role, personality, and behavior. This message guides how the agent responds and interacts.\n",
    "\n",
    " - **`llm_config`**:  \n",
    "   Configuration for the language model. This can be provided directly or via a context manager, and determines which LLM the agent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b325bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# Create LLM configuration first\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create the agent using the context manager approach\n",
    "my_agent = ConversableAgent(\n",
    "    name=\"helpful_agent\",  # Give your agent a unique name\n",
    "    system_message=\"You are a helpful AI assistant\",  # Define its personality and purpose\n",
    "    llm_config=llm_config  # Pass the LLM configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78636d",
   "metadata": {},
   "source": [
    "**Interacting with a ConversableAgent**\n",
    "- The simplest way to interact with a ConversableAgent is to use the run() and process() methods. Here's a basic example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793c7e3",
   "metadata": {},
   "source": [
    " ### Why Two Steps? `run()` and `process()`\n",
    " \n",
    " When you call `run()`, it does **not** immediately return the final output. Instead, it gives you an **iterator**‚Äîa special object that streams events, messages, and metadata as the conversation unfolds.\n",
    " \n",
    " The `process()` method is a convenient helper that automatically iterates through these events for you. It simulates a chat-like console experience: printing messages, handling user input, and making the interaction feel live and conversational.\n",
    " \n",
    " **Summary:**\n",
    " \n",
    " - Use **`run()`** and manually iterate over the events if you want **full control** over the workflow and how each event is handled.\n",
    " - Use **`process()`** (typically in combination with `run()`) for a **quick, ready-to-use chat experience** in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the workflow\n",
    "response = my_agent.run(\n",
    "    message=\"What's the capital of France?\",\n",
    "    max_turns=2,  # Limit conversation length\n",
    "    user_input=True  # Allow user to provide input\n",
    ")\n",
    "\n",
    "# Process the workflow\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8be05a",
   "metadata": {},
   "source": [
    "### üè¶ Financial Compliance Example\n",
    "\n",
    "Let's build a simple **financial agent** using `ConversableAgent` to help analyze transactions and discuss compliance topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964949be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "import os\n",
    "\n",
    "# Configure the LLM (we created this in the previous section)\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Create a basic financial agent\n",
    "with llm_config:\n",
    "    finance_agent = ConversableAgent(\n",
    "        name=\"finance_agent\",\n",
    "        system_message=\"You are a financial assistant who helps analyze financial data and transactions.\"\n",
    "    )\n",
    "\n",
    "# Run the agent with a prompt\n",
    "response = finance_agent.run(\n",
    "    message=\"Can you explain what makes a transaction suspicious?\",\n",
    "    max_turns=1\n",
    ")\n",
    "\n",
    "# Iterate through the chat automatically with console output\n",
    "response.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
