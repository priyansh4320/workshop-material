{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641dfddb",
   "metadata": {},
   "source": [
    "# Core Concepts and Architectures in Ag2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b295c47",
   "metadata": {},
   "source": [
    "In this module, we will explore the fundamental concepts of ag2 and examine various agent architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06511633",
   "metadata": {},
   "source": [
    "# Core Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190eec5",
   "metadata": {},
   "source": [
    "## ConversableAgent\n",
    "\n",
    "A class for generic conversable agents which can be configured as assistant or user proxy.\n",
    "\n",
    "After receiving each message, the agent will send a reply to the sender unless the msg is a termination msg. For example, AssistantAgent and UserProxyAgent are subclasses of this class, configured with different default settings.\n",
    "\n",
    "```\n",
    "ConversableAgent(\n",
    "    name, \n",
    "    system_message='You are a helpful AI Assistant.', \n",
    "    is_termination_msg=None, max_consecutive_auto_reply=None, \n",
    "    human_input_mode='TERMINATE', \n",
    "    function_map=None, \n",
    "    code_execution_config=False, \n",
    "    llm_config=None, \n",
    "    default_auto_reply='', \n",
    "    description=None, \n",
    "    chat_messages=None, \n",
    "    silent=None, \n",
    "    context_variables=None, \n",
    "    functions=None, \n",
    "    update_agent_state_before_reply=None, \n",
    "    handoffs=None\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fe1b3",
   "metadata": {},
   "source": [
    "**Args:**\n",
    "- `name` (`str`): Name of the agent.\n",
    "- `system_message` (`str` or `list`): System message for ChatCompletion inference.\n",
    "- `is_termination_msg` (`function`): Function that takes a message (as a `dict`) and returns a boolean indicating if the message is a termination message. The dict can contain the following keys: `\"content\"`, `\"role\"`, `\"name\"`, `\"function_call\"`.\n",
    "- `max_consecutive_auto_reply` (`int`): Maximum number of consecutive auto replies. Defaults to `None` (no limit; class attribute `MAX_CONSECUTIVE_AUTO_REPLY` will be used). If set to `0`, no auto reply will be generated.\n",
    "- `human_input_mode` (`str`): Determines when to prompt for human input. Possible values:\n",
    "    - `\"ALWAYS\"`: Prompts for human input every time a message is received. Conversation stops when human input is `\"exit\"`, or when `is_termination_msg` is `True` and there is no human input.\n",
    "    - `\"TERMINATE\"`: Prompts for human input only when a termination message is received or the number of auto replies reaches `max_consecutive_auto_reply`.\n",
    "    - `\"NEVER\"`: Never prompts for human input. Conversation stops when the number of auto replies reaches `max_consecutive_auto_reply` or when `is_termination_msg` is `True`.\n",
    "- `function_map` (`dict[str, callable]`): Maps function names (passed to OpenAI) to callable functions, also used for tool calls.\n",
    "- `code_execution_config` (`dict` or `False`): Configuration for code execution. To disable, set to `False`. Otherwise, provide a dictionary with the following optional keys:\n",
    "    - `work_dir` (`str`, optional): Working directory for code execution. If `None`, a default directory is used (the \"extensions\" directory under `path_to_autogen`).\n",
    "    - `use_docker` (`list`, `str`, or `bool`, optional): Docker image(s) to use for code execution. Default is `True` (uses a default list of images). If a list or string of image names is provided, the first successfully pulled image is used. If `False`, code executes in the current environment. **Docker is strongly recommended.**\n",
    "    - `timeout` (`int`, optional): Maximum execution time in seconds.\n",
    "    - `last_n_messages` (`int` or `str`, experimental): Number of messages to look back for code execution. If set to `'auto'`, scans all messages since the agent last spoke (default: `'auto'`).\n",
    "- `llm_config` (`LLMConfig`, `dict`, `False`, or `None`): LLM inference configuration. See `OpenAIWrapper.create` for options. When using OpenAI or Azure OpenAI endpoints, specify a non-empty `'model'` in `llm_config` or in each config of `'config_list'`. To disable LLM-based auto reply, set to `False`. If `None`, uses `self.DEFAULT_CONFIG` (defaults to `False`).\n",
    "- `default_auto_reply` (`str` or `dict`): Default auto reply when no code execution or LLM-based reply is generated.\n",
    "- `description` (`str`): Short description of the agent. Used by other agents (e.g., `GroupChatManager`) to decide when to call this agent. Defaults to `system_message`.\n",
    "- `chat_messages` (`dict` or `None`): Previous chat messages with other agents. Can be used to give the agent memory by providing chat history, allowing it to resume previous conversations. Defaults to an empty chat history.\n",
    "- `silent` (`bool` or `None`): *(Experimental)* Whether to print the message sent. If `None`, uses the value of `silent` in each function.\n",
    "- `context_variables` (`ContextVariables` or `None`): Context variables providing persistent context for the agent. This is a reference to a shared context for multi-agent chats. Behaves like a dictionary (`dict[str, Any]`).\n",
    "- `functions` (`List[Callable[..., Any]]`): List of functions to register with the agent. These are wrapped as tools and registered for LLM (not execution).\n",
    "- `update_agent_state_before_reply` (`List[Callable[..., Any]]`): List of functions (including `UpdateSystemMessage`s) called to update the agent before it replies.\n",
    "- `handoffs` (`Handoffs`): Handoffs object containing all handoff transition conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd89f34",
   "metadata": {},
   "source": [
    "## AsistantAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f08276c",
   "metadata": {},
   "source": [
    "Assistant agent, designed to solve a task with LLM.\n",
    "\n",
    "AssistantAgent is a subclass of ConversableAgent configured with a default system message. The default system message is designed to solve a task with LLM, including suggesting python code blocks and debugging. human_input_mode is default to \"NEVER\" and code_execution_config is default to False. This agent doesn't execute code by default, and expects the user to execute the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f02bb",
   "metadata": {},
   "source": [
    "```\n",
    "AssistantAgent(\n",
    "    name, \n",
    "    system_message=DEFAULT_SYSTEM_MESSAGE, \n",
    "    llm_config=None, is_termination_msg=None, \n",
    "    max_consecutive_auto_reply=None, human_input_mode='NEVER', \n",
    "    description=None, \n",
    "    **kwargs\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832860f2",
   "metadata": {},
   "source": [
    "**Args:**\n",
    "- `name` (str): Agent name.\n",
    "- `system_message` (str): System message for ChatCompletion inference. Override this attribute to reprogram the agent.\n",
    "- `llm_config` (dict, False, or None): LLM inference configuration. See `OpenAIWrapper.create` for available options.\n",
    "- `is_termination_msg` (function): Function that takes a message (dict) and returns a boolean indicating if the message is a termination message. The dict may contain the keys: `\"content\"`, `\"role\"`, `\"name\"`, `\"function_call\"`.\n",
    "- `max_consecutive_auto_reply` (int): Maximum number of consecutive auto replies. Defaults to `None` (no limit; class attribute `MAX_CONSECUTIVE_AUTO_REPLY` will be used). This limit only applies when `human_input_mode` is not `\"ALWAYS\"`.\n",
    "- `**kwargs` (dict): Additional keyword arguments. See other kwargs in `ConversableAgent`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42497d43",
   "metadata": {},
   "source": [
    "## UserProxyAgent\n",
    "\n",
    "UserProxyAgent is a subclass of ConversableAgent configured with human_input_mode to ALWAYS and llm_config to False. By default, the agent will prompt for human input every time a message is received. Code execution is enabled by default. LLM-based auto reply is disabled by default. To modify auto reply, register a method with register_reply. To modify the way to get human input, override get_human_input method. To modify the way to execute code blocks, single code block, or function call, override execute_code_blocks, run_code, and execute_function methods respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a4fea",
   "metadata": {},
   "source": [
    "```\n",
    "UserProxyAgent(\n",
    "    name,\n",
    "    is_termination_msg=None,\n",
    "    max_consecutive_auto_reply=None,\n",
    "    human_input_mode='ALWAYS',\n",
    "    function_map=None,\n",
    "    code_execution_config={},\n",
    "    default_auto_reply='',\n",
    "    llm_config=False,\n",
    "    system_message='',\n",
    "    description=None, **kwargs\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe82b0",
   "metadata": {},
   "source": [
    "**Args:**\n",
    "\n",
    "- `name` (`str`): Name of the agent.\n",
    "- `is_termination_msg` (`function`): A function that takes a message (as a `dict`) and returns a boolean indicating if the message is a termination message. The dict may contain the following keys: `\"content\"`, `\"role\"`, `\"name\"`, `\"function_call\"`.\n",
    "- `max_consecutive_auto_reply` (`int`, optional): Maximum number of consecutive auto replies. Defaults to `None` (no limit; class attribute `MAX_CONSECUTIVE_AUTO_REPLY` will be used). This limit only applies when `human_input_mode` is not `\"ALWAYS\"`.\n",
    "- `human_input_mode` (`str`): Determines when to prompt for human input. Possible values:\n",
    "    - `\"ALWAYS\"`: Prompts for human input every time a message is received. Conversation stops when the human input is `\"exit\"`, or when `is_termination_msg` is `True` and there is no human input.\n",
    "    - `\"TERMINATE\"`: Prompts for human input only when a termination message is received or the number of auto replies reaches `max_consecutive_auto_reply`.\n",
    "    - `\"NEVER\"`: Never prompts for human input. Conversation stops when the number of auto replies reaches `max_consecutive_auto_reply` or when `is_termination_msg` is `True`.\n",
    "- `function_map` (`dict[str, callable]`): Maps function names (as passed to OpenAI) to callable functions.\n",
    "- `code_execution_config` (`dict` or `False`): Configuration for code execution. To disable code execution, set to `False`. Otherwise, provide a dictionary with the following keys:\n",
    "    - `work_dir` (`str`, optional): Working directory for code execution. If `None`, a default directory (`\"extensions\"` under `\"path_to_autogen\"`) is used.\n",
    "    - `use_docker` (`list`, `str`, or `bool`, optional): Docker image(s) to use for code execution. Default is `True` (uses a default list of images). If a list or string of image names is provided, the code will be executed in a Docker container with the first successfully pulled image. If `False`, code is executed in the current environment. **Docker is strongly recommended for code execution.**\n",
    "    - `timeout` (`int`, optional): Maximum execution time in seconds.\n",
    "    - `last_n_messages` (`int`, optional, experimental): Number of messages to look back for code execution. Defaults to `1`.\n",
    "- `default_auto_reply` (`str`, `dict`, or `None`): Default auto reply message when no code execution or LLM-based reply is generated.\n",
    "- `llm_config` (`LLMConfig`, `dict`, `False`, or `None`): LLM inference configuration.\n",
    "- `system_message` (`str` or `List`): system message for ChatCompletion inference. Only used when llm_config is not False. Use it to reprogram the agent.\n",
    "- `description` (`str`): a short description of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d2cc4",
   "metadata": {},
   "source": [
    "## GroupChat\n",
    "\n",
    "AutoGen provides a more general conversation pattern called group chat, which involves more than two agents.\n",
    "\n",
    "The core idea of group chat is that all agents contribute to a single conversation thread and share the same context.\n",
    "\n",
    "This is useful for tasks that require collaboration among multiple agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dff5b",
   "metadata": {},
   "source": [
    "```\n",
    "GroupChat(\n",
    "    agents,\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    admin_name='Admin',\n",
    "    func_call_filter=True,\n",
    "    speaker_selection_method='auto',\n",
    "    max_retries_for_selecting_speaker=2,\n",
    "    allow_repeat_speaker=None,\n",
    "    allowed_or_disallowed_speaker_transitions=None,\n",
    "    speaker_transitions_type=None,\n",
    "    enable_clear_history=False,\n",
    "    send_introductions=False,\n",
    "    select_speaker_message_template=(\n",
    "        \"You are in a role play game. The following roles are available:\\n\"\n",
    "        \"  {roles}.\\n\"\n",
    "        \"Read the following conversation.\\n\"\n",
    "        \"Then select the next role from {agentlist} to play. Only return the role.\"\n",
    "    ),\n",
    "    select_speaker_prompt_template=SELECT_SPEAKER_PROMPT_TEMPLATE,\n",
    "    select_speaker_auto_multiple_template=(\n",
    "        \"You provided more than one name in your text, please return just the name of the next speaker. \"\n",
    "        \"To determine the speaker use these prioritised rules:\\n\"\n",
    "        \"  1. If the context refers to themselves as a speaker e.g. \\\"As the...\\\", choose that speaker's name\\n\"\n",
    "        \"  2. If it refers to the \\\"next\\\" speaker name, choose that name\\n\"\n",
    "        \"  3. Otherwise, choose the first provided speaker's name in the context\\n\"\n",
    "        \"The names are case-sensitive and should not be abbreviated or changed.\\n\"\n",
    "        \"Respond with ONLY the name of the speaker and DO NOT provide a reason.\"\n",
    "    ),\n",
    "    select_speaker_auto_none_template=(\n",
    "        \"You didn't choose a speaker. As a reminder, to determine the speaker use these prioritised rules:\\n\"\n",
    "        \"  1. If the context refers to themselves as a speaker e.g. \\\"As the...\\\", choose that speaker's name\\n\"\n",
    "        \"  2. If it refers to the \\\"next\\\" speaker name, choose that name\\n\"\n",
    "        \"  3. Otherwise, choose the first provided speaker's name in the context\\n\"\n",
    "        \"The names are case-sensitive and should not be abbreviated or changed.\\n\"\n",
    "        \"The only names that are accepted are {agentlist}.\\n\"\n",
    "        \"Respond with ONLY the name of the speaker and DO NOT provide a reason.\"\n",
    "    ),\n",
    "    select_speaker_transform_messages=None,\n",
    "    select_speaker_auto_verbose=False,\n",
    "    select_speaker_auto_model_client_cls=None,\n",
    "    select_speaker_auto_llm_config=None,\n",
    "    role_for_select_speaker_messages='system'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac60e3",
   "metadata": {},
   "source": [
    "**GroupChat Class Args**\n",
    "- **agents**:  \n",
    "  List of participating agents.\n",
    "- **messages**:  \n",
    "  List of messages in the group chat.\n",
    "- **max_round**:  \n",
    "  Maximum number of rounds.\n",
    "- **admin_name**:  \n",
    "  Name of the admin agent (default: `\"Admin\"`).  \n",
    "  If a `KeyboardInterrupt` occurs, the admin agent will take over.\n",
    "- **func_call_filter**:  \n",
    "  Whether to enforce function call filtering (default: `True`).  \n",
    "  If `True` and a message is a function call suggestion, the next speaker will be chosen from agents whose `function_map` contains the corresponding function name.\n",
    "- **select_speaker_message_template**:  \n",
    "  Customizes the select speaker message (used in `\"auto\"` speaker selection).  \n",
    "  Appears first in the message context and generally includes agent descriptions and the list of agents.  \n",
    "  - If the string contains `{roles}`, it will be replaced with the agents and their role descriptions.  \n",
    "  - If the string contains `{agentlist}`, it will be replaced with a comma-separated list of agent names in square brackets.  \n",
    "  - **Default:**  \n",
    "    `\"You are in a role play game. The following roles are available: {roles}. Read the following conversation. Then select the next role from {agentlist} to play. Only return the role.\"`\n",
    "- **select_speaker_prompt_template**:  \n",
    "  Customizes the select speaker prompt (used in `\"auto\"` speaker selection).  \n",
    "  Appears last in the message context and generally includes the list of agents and guidance for the LLM to select the next agent.  \n",
    "  - If the string contains `{agentlist}`, it will be replaced with a comma-separated list of agent names in square brackets.  \n",
    "  - **Default:**  \n",
    "    `\"Read the above conversation. Then select the next role from {agentlist} to play. Only return the role.\"`  \n",
    "  - To ignore this prompt, set to `None`. If set to `None`, ensure your instructions for selecting a speaker are in the `select_speaker_message_template`.\n",
    "- **select_speaker_auto_multiple_template**:  \n",
    "  Customizes the follow-up prompt used when selecting a speaker fails with a response containing multiple agent names.  \n",
    "  Guides the LLM to return just one agent name. Applies only to `\"auto\"` speaker selection.  \n",
    "  - If the string contains `{agentlist}`, it will be replaced with a comma-separated list of agent names in square brackets.  \n",
    "  - **Default:**  \n",
    "    ```\n",
    "    You provided more than one name in your text, please return just the name of the next speaker. To determine the speaker use these prioritised rules:\n",
    "      1. If the context refers to themselves as a speaker e.g. \"As the...\", choose that speaker's name\n",
    "      2. If it refers to the \"next\" speaker name, choose that name\n",
    "      3. Otherwise, choose the first provided speaker's name in the context\n",
    "    The names are case-sensitive and should not be abbreviated or changed.\n",
    "    Respond with ONLY the name of the speaker and DO NOT provide a reason.\n",
    "    ```\n",
    "- **select_speaker_auto_none_template**:  \n",
    "  Customizes the follow-up prompt used when selecting a speaker fails with a response containing no agent names.  \n",
    "  Guides the LLM to return an agent name and provides a list of agent names. Applies only to `\"auto\"` speaker selection.  \n",
    "  - If the string contains `{agentlist}`, it will be replaced with a comma-separated list of agent names in square brackets.  \n",
    "  - **Default:**  \n",
    "    ```\n",
    "    You didn't choose a speaker. As a reminder, to determine the speaker use these prioritised rules:\n",
    "      1. If the context refers to themselves as a speaker e.g. \"As the...\", choose that speaker's name\n",
    "      2. If it refers to the \"next\" speaker name, choose that name\n",
    "      3. Otherwise, choose the first provided speaker's name in the context\n",
    "    The names are case-sensitive and should not be abbreviated or changed.\n",
    "    The only names that are accepted are {agentlist}.\n",
    "    Respond with ONLY the name of the speaker and DO NOT provide a reason.\n",
    "    ```\n",
    "- **speaker_selection_method**:  \n",
    "  Method for selecting the next speaker (default: `\"auto\"`).  \n",
    "  Can be any of the following (case-insensitive, raises `ValueError` if not recognized):\n",
    "  - `\"auto\"`: Next speaker is selected automatically by LLM.\n",
    "  - `\"manual\"`: Next speaker is selected manually by user input.\n",
    "  - `\"random\"`: Next speaker is selected randomly.\n",
    "  - `\"round_robin\"`: Next speaker is selected in a round robin fashion (iterating in the same order as provided in agents).\n",
    "  - A custom speaker selection function (`Callable`):  \n",
    "    The function will be called to select the next speaker. It should take the last speaker and the group chat as input and return one of the following:\n",
    "    1. An `Agent` instance (must be one of the agents in the group chat).\n",
    "    2. A string from `['auto', 'manual', 'random', 'round_robin']` to select a default method.\n",
    "    3. `None`, which will terminate the conversation gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1e29e",
   "metadata": {},
   "source": [
    "## GroupChatManager\n",
    "\n",
    "A chat manager agent that can manage a group chat of multiple agents.A group chat is orchestrated by a special agent type GroupChatManager. In the first step of the group chat, the Group Chat Manager selects an agent to speak. Then, the selected agent speaks and the message is sent back to the Group Chat Manager, who broadcasts the message to all other agents in the group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e60b90",
   "metadata": {},
   "source": [
    "Currently, the following strategies are supported:\n",
    "\n",
    "1) `round_robin`: The Group Chat Manager selects agents in a round-robin fashion based on the order of 2)the agents provided.\n",
    "2) `random`: The Group Chat Manager selects agents randomly.\n",
    "3) `manual`: The Group Chat Manager selects agents by asking for human input.\n",
    "4) `auto`: The default strategy, which selects agents using the Group Chat Manager's LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2094e6",
   "metadata": {},
   "source": [
    "```\n",
    "GroupChatManager(\n",
    "    groupchat,\n",
    "    name='chat_manager',\n",
    "    max_consecutive_auto_reply=maxsize,\n",
    "    human_input_mode='NEVER',\n",
    "    system_message='Group chat manager.',\n",
    "    silent=False, **kwargs\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf8158",
   "metadata": {},
   "source": [
    "## Tools and Functions\n",
    "\n",
    "Tools provide specialized capabilities to your agents, allowing them to perform actions and make decisions within the Group Chat environment. Similar to how real-world professionals use tools to accomplish specific tasks, AG2 agents use tools to extend their functionality beyond simple conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ceed77",
   "metadata": {},
   "source": [
    "### ReplyResult: The Key to Tool Operations#\n",
    "The core component of tools is the ReplyResult object, which represents the outcome of a tool's operation and has three key properties:\n",
    "\n",
    "- `message`: The text response to be shown in the conversation\n",
    "- `target`: (Optional) Where control should go next\n",
    "- `context_variables`: (Optional) Updated shared state (we'll explore this in the next section)\n",
    "This simple but powerful structure allows tools to both communicate results and influence the conversation flow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat.group import ReplyResult\n",
    "\n",
    "# Define a query classification tool\n",
    "def classify_query(query: str) -> ReplyResult:\n",
    "    \"\"\"Classify a user query as technical or general.\"\"\"\n",
    "\n",
    "    # Simple keyword-based classification\n",
    "    technical_keywords = [\"error\", \"bug\", \"broken\", \"crash\", \"not working\", \"shutting down\"]\n",
    "\n",
    "    # Check if any technical keywords are in the query\n",
    "    if any(keyword in query.lower() for keyword in technical_keywords):\n",
    "        return ReplyResult(\n",
    "            message=\"This appears to be a technical issue.\"\n",
    "        )\n",
    "    else:\n",
    "        return ReplyResult(\n",
    "            message=\"This appears to be a general question.\",\n",
    "        )\n",
    "\n",
    "# Create the triage agent with the tool\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "with llm_config:\n",
    "    triage_agent = ConversableAgent(\n",
    "        name=\"triage_agent\",\n",
    "        system_message=\"\"\"You are a triage agent. For each user query,\n",
    "        identify whether it is a technical issue or a general question.\n",
    "        Use the classify_query tool to categorize queries and route them appropriately.\n",
    "        Do not provide suggestions or answers, only route the query.\"\"\",\n",
    "        functions=[classify_query]  # Register the function with the agent\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64675a05",
   "metadata": {},
   "source": [
    "### register_for_llm and register_for_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64dca6",
   "metadata": {},
   "source": [
    "1) register_for_llm: Decorator factory for registering a function to be used by an agent.\n",
    "\n",
    "It's return value is used to decorate a function to be registered to the agent. The function uses type hints to specify the arguments and return type. The function name is used as the default name for the function, but a custom name can be provided. The function description is used to describe the function in the agent's configuration.\n",
    "```\n",
    "register_for_llm(\n",
    "    *, \n",
    "    name=None, \n",
    "    description=None,\n",
    "    api_style='tool', \n",
    "    silent_override=False\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845df3d",
   "metadata": {},
   "source": [
    "2. register_for_execution: Decorator factory for registering a function to be executed by an agent.\n",
    "\n",
    "It's return value is used to decorate a function to be registered to the agent.\n",
    "\n",
    "```\n",
    "register_for_execution(\n",
    "    name=None, \n",
    "    description=None,\n",
    "     *, \n",
    "     serialize=True, \n",
    "     silent_override=False\n",
    "     )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96addee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "from typing import Annotated\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "@agent1.register_for_llm(description=\"This is a very useful function\")\n",
    "def my_function(a: Annotated[str, \"description of a parameter\"] = \"a\", b: int=2, c=3.14):\n",
    "     return a + str(b * c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a58714",
   "metadata": {},
   "source": [
    "## Context Variable\n",
    "\n",
    "Context Variables provide shared memory for your agents, allowing them to maintain state across a conversation and make decisions based on that shared information. If tools are the specialized capabilities agents can use, context variables are their collective knowledge base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada21402",
   "metadata": {},
   "source": [
    "Context Variables are a structured way to store and share information between agents in a group chat. They act as a persistent memory that:\n",
    "\n",
    "- Maintains state throughout the entire conversation\n",
    "- Is accessible to all agents in the group\n",
    "- Can be read and updated by any agent or tool\n",
    "- Stores data in a key-value format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a75d1",
   "metadata": {},
   "source": [
    "Context variables in AG2 are implemented through the ContextVariables class, which provides a dictionary-like interface to store and retrieve values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5e087",
   "metadata": {},
   "source": [
    "```\n",
    "from autogen.agentchat.group import ContextVariables\n",
    "\n",
    "# Create context variables\n",
    "context = ContextVariables(data={\n",
    "    \"user_name\": \"Alex\",\n",
    "    \"issue_count\": 0,\n",
    "    \"previous_issues\": []\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6809a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.group import ContextVariables\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "\n",
    "# Initialize context variables with initial data\n",
    "context = ContextVariables(data={\n",
    "    \"user_name\": \"Alex\",\n",
    "    \"issue_count\": 0,\n",
    "    \"previous_issues\": []\n",
    "})\n",
    "\n",
    "# Create pattern with the context variables\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=triage_agent,\n",
    "    agents=[triage_agent, tech_agent, general_agent],\n",
    "    user_agent=user,\n",
    "    context_variables=context,\n",
    "    group_manager_args={\"llm_config\": llm_config}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebf888",
   "metadata": {},
   "source": [
    "Reading and Writing Context Values:\n",
    "- The ContextVariables class provides several methods for reading and writing values:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60525b",
   "metadata": {},
   "source": [
    "1) Reading values\n",
    "```\n",
    "user_name = context.get(\"user_name\")  # Returns \"Alex\"\n",
    "non_existent = context.get(\"non_existent\", \"default\")  # Returns \"default\"\n",
    "```\n",
    "2) Writing values\n",
    "```\n",
    "context.set(\"issue_count\", 1)  # Sets issue_count to 1\n",
    "context.update({\"last_login\": \"2023-05-01\", \"premium\": True})  # Update multiple values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274fa75",
   "metadata": {},
   "source": [
    "> Context variables are not automatically included in the prompts sent to LLMs. Unlike conversation history, which is always visible, context variables remain in AG2's memory layer and must be explicitly accessed through specific mechanisms provided by the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db8138",
   "metadata": {},
   "source": [
    "### Three Access Methods\n",
    "There are three primary ways agents can access context variables:\n",
    "\n",
    "1. Through Tools with Context Parameters: \n",
    "- The most common method is through tools that have a context_variables parameter. AG2's dependency injection automatically provides the current context:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab157fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_user_history(\n",
    "    query: str,\n",
    "    context_variables: ContextVariables  # AG2 injects this automatically\n",
    ") -> str:\n",
    "    \"\"\"Check user's previous issues and provide personalized help.\"\"\"\n",
    "    user_name = context_variables.get(\"user_name\", \"User\")\n",
    "    issue_count = context_variables.get(\"issue_count\", 0)\n",
    "\n",
    "    if issue_count > 3:\n",
    "        return f\"I see you've had {issue_count} issues today, {user_name}. Let me escalate this to a senior technician.\"\n",
    "    else:\n",
    "        return f\"Let me help you with this issue, {user_name}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742d046",
   "metadata": {},
   "source": [
    "2. Using System Message Templates:\n",
    "- For critical context that agents should always be aware of, use the UpdateSystemMessage feature to dynamically update the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import UpdateSystemMessage\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"support_agent\",\n",
    "    system_message=\"You are a helpful support agent.\",\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You are helping {user_name} (Premium: {is_premium}). \"\n",
    "            \"They have reported {issue_count} issues in this session. \"\n",
    "            \"Current issue type: {issue_type}\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9935a",
   "metadata": {},
   "source": [
    "3. Creating Context Summary Tools:\n",
    "- For complex contexts, create dedicated tools that summarize the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_summary(context_variables: ContextVariables) -> str:\n",
    "    \"\"\"Get a summary of the current support session.\"\"\"\n",
    "    summary = f\"\"\"\n",
    "    Session Summary:\n",
    "    - User: {context_variables.get('user_name', 'Unknown')}\n",
    "    - Session Duration: {calculate_duration(context_variables.get('session_start'))}\n",
    "    - Issues Reported: {context_variables.get('issue_count', 0)}\n",
    "    - Current Status: {context_variables.get('status', 'Active')}\n",
    "    - Last Action: {context_variables.get('last_action', 'None')}\n",
    "    \"\"\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4075f",
   "metadata": {},
   "source": [
    "Best Practices\n",
    "- Tools: Best for dynamic context access during specific operations\n",
    "- System Messages: Ideal for context that agents should always be aware of\n",
    "- Templates: Keep concise to avoid token bloat\n",
    "- Documentation: Clearly define your context structure\n",
    "- Summaries: Consider context summary tools for complex applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2757990",
   "metadata": {},
   "source": [
    "### Handoffs\n",
    "Handoffs define the paths a conversation can take through your multi-agent system. They allow you to create sophisticated workflows where the right agent handles each part of a conversation at the right time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfb42a",
   "metadata": {},
   "source": [
    "Each agent in AG2 has a handoffs attribute that manages transitions from that agent. The handoffs attribute is an instance of the Handoffs class, which provides methods for defining when and where control should pass:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552812f2",
   "metadata": {},
   "source": [
    "```\n",
    "# Access an agent's handoffs\n",
    "my_agent.handoffs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d68a4",
   "metadata": {},
   "source": [
    "**Transition Targets**\n",
    "\n",
    "When defining a handoff, you specify a **transition target**—the destination where control should go next. AG2 provides several types of transition targets:\n",
    "\n",
    "- **AgentNameTarget**: Transfer control to an agent by name.\n",
    "- **AgentTarget**: Transfer control to a specific agent instance.\n",
    "- **AskUserTarget**: Ask the user to select the next speaker.\n",
    "- **NestedChatTarget**: Represents a nested chat configuration as the target.\n",
    "- **GroupManagerTarget**: Transfer control to the group manager, who will select the next speaker.\n",
    "- **GroupChatTarget**: Transfer control to another group chat (essentially a nested group chat).\n",
    "- **RandomAgentTarget**: Randomly select the next agent from a list.\n",
    "- **RevertToUserTarget**: Return control to the user agent.\n",
    "- **StayTarget**: Keep control with the current agent.\n",
    "- **TerminateTarget**: End the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c85a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.group import AgentTarget, RevertToUserTarget, TerminateTarget\n",
    "\n",
    "# Transition to a specific agent\n",
    "target = AgentTarget(tech_agent)\n",
    "\n",
    "# Return to the user\n",
    "target = RevertToUserTarget()\n",
    "\n",
    "# End the conversation\n",
    "target = TerminateTarget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2acfc1",
   "metadata": {},
   "source": [
    "**ReplyResults and Transitions**\n",
    "- Each tool function can return a ReplyResult that specifies a transition target:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4341980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tool_function(param: str, context_variables: ContextVariables) -> ReplyResult:\n",
    "    return ReplyResult(\n",
    "        message=\"Tool result message\",\n",
    "        target=AgentTarget(next_agent),  # Where to go next\n",
    "        context_variables=context_variables  # Updated context\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118b512",
   "metadata": {},
   "source": [
    "## Types of Handoffs\n",
    "\n",
    "AG2 offers four main ways to define handoffs:\n",
    "\n",
    "1. **LLM-based conditions**  \n",
    "   Transitions based on the language model's analysis of messages.\n",
    "   ```\n",
    "   from autogen.agentchat.group import OnCondition, StringLLMCondition\n",
    "\n",
    "   # Set up LLM-based handoffs for the triage agent\n",
    "   triage_agent.handoffs.add_llm_conditions([\n",
    "         OnCondition(\n",
    "            target=AgentTarget(tech_agent),\n",
    "            condition=StringLLMCondition(prompt=\"When the user query is related to technical issues.\"),\n",
    "         ),\n",
    "         OnCondition(\n",
    "            target=AgentTarget(general_agent),\n",
    "            condition=StringLLMCondition(prompt=\"When the user query is related to general questions.\"),\n",
    "         )\n",
    "      ])\n",
    "   ```\n",
    "\n",
    "2. **Context-based conditions**  \n",
    "   Transitions based on values in context variables.\n",
    "   ```\n",
    "   from autogen.agentchat.group import OnContextCondition, ExpressionContextCondition, ContextExpression\n",
    "\n",
    "   # Set up context-based handoffs for the tech agent\n",
    "   tech_agent.handoffs.add_context_condition(\n",
    "      OnContextCondition(\n",
    "         target=AgentTarget(escalation_agent),\n",
    "         condition=ExpressionContextCondition(\n",
    "               expression=ContextExpression(\"${issue_severity} >= 8\")\n",
    "         )\n",
    "      )\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **After-work behavior**  \n",
    "   Default transition when no LLM or context conditions are met and no tools are called.\n",
    "   ```\n",
    "   # Set the default after-work transition\n",
    "   tech_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "   ```\n",
    "\n",
    "4. **Explicit handoffs from tools**  \n",
    "   Direct transitions specified by tool return values.\n",
    "   ```\n",
    "   def classify_query(query: str, context_variables: ContextVariables) -> ReplyResult:\n",
    "      if is_technical:\n",
    "         return ReplyResult(\n",
    "               message=\"This is a technical issue.\",\n",
    "               target=AgentTarget(tech_agent),\n",
    "               context_variables=context_variables\n",
    "         )\n",
    "      else:\n",
    "         return ReplyResult(\n",
    "               message=\"This is a general question.\",\n",
    "               target=AgentTarget(general_agent),\n",
    "               context_variables=context_variables\n",
    "         )\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fee429",
   "metadata": {},
   "source": [
    "### Complete Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac79613",
   "metadata": {},
   "source": [
    "Setting Up the Initial Structure\n",
    "- First, let's create our context variables and agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.agentchat.group import (\n",
    "    ContextVariables, ReplyResult, AgentTarget,\n",
    "    OnCondition, StringLLMCondition,\n",
    "    OnContextCondition, ExpressionContextCondition, ContextExpression,\n",
    "    RevertToUserTarget\n",
    ")\n",
    "\n",
    "# Initialize context variables for our support system\n",
    "support_context = ContextVariables(data={\n",
    "    \"query_count\": 0,\n",
    "    \"repeat_issue\": False,\n",
    "    \"previous_solutions\": [],\n",
    "    \"issue_type\": \"\",\n",
    "    \"issue_subtype\": \"\",\n",
    "})\n",
    "\n",
    "# Configure the LLM\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create all our support agents\n",
    "with llm_config:\n",
    "    # Main triage agent - the starting point for all user queries\n",
    "    triage_agent = ConversableAgent(\n",
    "        name=\"triage_agent\",\n",
    "        system_message=\"\"\"You are a support triage agent. Your role is to:\n",
    "        1. Determine if a query is technical or general\n",
    "        2. Use the classify_query function to route appropriately\n",
    "\n",
    "        Do not attempt to solve issues yourself - your job is proper routing.\"\"\"\n",
    "    )\n",
    "\n",
    "    # General support for non-technical questions\n",
    "    general_agent = ConversableAgent(\n",
    "        name=\"general_agent\",\n",
    "        system_message=\"\"\"You are a general support agent who handles non-technical questions.\n",
    "        If the user is a premium customer (check account_tier context variable),\n",
    "        you should transfer them directly to the premium support agent.\n",
    "        Otherwise, provide helpful responses to general inquiries.\"\"\"\n",
    "    )\n",
    "\n",
    "    # Tech agent for initial technical assessment\n",
    "    tech_agent = ConversableAgent(\n",
    "        name=\"tech_agent\",\n",
    "        system_message=\"\"\"You are a technical support agent who handles the initial assessment\n",
    "        of all technical issues.\n",
    "\n",
    "        If the user is a premium customer (check account_tier context variable),\n",
    "        you should transfer them directly to the premium support agent.\n",
    "\n",
    "        Otherwise, determine if the issue is related to:\n",
    "        - Computer issues (laptops, desktops, PCs, Macs)\n",
    "        - Smartphone issues (iPhones, Android phones, tablets)\n",
    "\n",
    "        And route to the appropriate specialist.\"\"\"\n",
    "    )\n",
    "\n",
    "    # Device-specific agents\n",
    "    computer_agent = ConversableAgent(\n",
    "        name=\"computer_agent\",\n",
    "        system_message=\"\"\"You are a computer specialist who handles issues with laptops, desktops,\n",
    "        PCs, and Macs. You provide troubleshooting for hardware and software issues specific to\n",
    "        computers. You're knowledgeable about Windows, macOS, Linux, and common computer peripherals.\n",
    "\n",
    "        For first-time issues, provide a solution directly.\n",
    "\n",
    "        If a user returns and says they tried your solution but are still having the issue,\n",
    "        use the check_repeat_issue function to escalate to advanced troubleshooting. Do not provide a solution\n",
    "        yourself for returning users, simply route it to advanced troubleshooting.\"\"\"\n",
    "    )\n",
    "\n",
    "    smartphone_agent = ConversableAgent(\n",
    "        name=\"smartphone_agent\",\n",
    "        system_message=\"\"\"You are a smartphone specialist who handles issues with mobile devices\n",
    "        including iPhones, Android phones, and tablets. You're knowledgeable about iOS, Android,\n",
    "        mobile apps, battery issues, screen problems, and connectivity troubleshooting.\n",
    "\n",
    "        For first-time issues, provide a solution directly.\n",
    "\n",
    "        If a user returns and says they tried your solution but are still having the issue,\n",
    "        use the check_repeat_issue function to escalate to advanced troubleshooting. Do not provide a solution\n",
    "        yourself for returning users, simply route it to advanced troubleshooting\"\"\"\n",
    "    )\n",
    "\n",
    "    # Advanced troubleshooting for complex issues\n",
    "    advanced_troubleshooting_agent = ConversableAgent(\n",
    "        name=\"advanced_troubleshooting_agent\",\n",
    "        system_message=\"\"\"You are an advanced troubleshooting specialist who handles complex,\n",
    "        persistent issues that weren't resolved by initial solutions. You provide deeper\n",
    "        diagnostic approaches and more comprehensive solutions for difficult technical problems.\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f74f8",
   "metadata": {},
   "source": [
    "Creating Tool Functions\n",
    "- Now let's define the tool functions that enable our agents to make routing decisions and update the conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool functions\n",
    "def classify_query(\n",
    "    query: Annotated[str, \"The user query to classify\"],\n",
    "    context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Classify a user query and route to the appropriate agent.\"\"\"\n",
    "    # Update query count\n",
    "    context_variables[\"query_count\"] += 1\n",
    "\n",
    "    # Simple classification logic\n",
    "    technical_keywords = [\"error\", \"bug\", \"broken\", \"crash\", \"not working\", \"shutting down\",\n",
    "                        \"frozen\", \"blue screen\", \"won't start\", \"slow\", \"virus\"]\n",
    "\n",
    "    if any(keyword in query.lower() for keyword in technical_keywords):\n",
    "        return ReplyResult(\n",
    "            message=\"This appears to be a technical issue. Let me route you to our tech support team.\",\n",
    "            target=AgentTarget(tech_agent),\n",
    "            context_variables=context_variables\n",
    "        )\n",
    "    else:\n",
    "        return ReplyResult(\n",
    "            message=\"This appears to be a general question. Let me connect you with our general support team.\",\n",
    "            target=AgentTarget(general_agent),\n",
    "            context_variables=context_variables\n",
    "        )\n",
    "\n",
    "def check_repeat_issue(\n",
    "    description: Annotated[str, \"User's description of the continuing issue\"],\n",
    "    context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Check if this is a repeat of an issue that wasn't resolved.\"\"\"\n",
    "    # Mark this as a repeat issue in the context\n",
    "    context_variables[\"repeat_issue\"] = True\n",
    "    context_variables[\"continuing_issue\"] = description\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"I understand that your issue wasn't resolved. Let me connect you with our advanced troubleshooting specialist.\",\n",
    "        target=AgentTarget(advanced_troubleshooting_agent),\n",
    "        context_variables=context_variables\n",
    "    )\n",
    "\n",
    "# Add tool functions to the appropriate agents\n",
    "triage_agent.functions = [classify_query]\n",
    "computer_agent.functions = [check_repeat_issue]\n",
    "smartphone_agent.functions = [check_repeat_issue]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6d6d1",
   "metadata": {},
   "source": [
    "Configuring  Handoffs\n",
    "\n",
    "1. We use LLM-based handoffs to route queries to the right specialist based on the content of the user's message (for example, whether the issue is about a computer or a smartphone).\n",
    "2. Context-based handoffs make decisions based on the state of the conversation rather than message content. We use these to detect when a customer returns with the same issue and escalate to advanced troubleshooting if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2ba3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route based on device type\n",
    "tech_agent.handoffs.add_llm_conditions([\n",
    "    OnCondition(\n",
    "        target=AgentTarget(computer_agent),\n",
    "        condition=StringLLMCondition(prompt=\"Route to computer specialist when the issue involves laptops, desktops, PCs, or Macs.\"),\n",
    "    ),\n",
    "    OnCondition(\n",
    "        target=AgentTarget(smartphone_agent),\n",
    "        condition=StringLLMCondition(prompt=\"Route to smartphone specialist when the issue involves phones, mobile devices, iOS, or Android.\"),\n",
    "    )\n",
    "])\n",
    "\n",
    "# For other tech issues, revert to user\n",
    "tech_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "\n",
    "# Configure handoffs for computer agent - for repeat issues\n",
    "computer_agent.handoffs.add_context_conditions([\n",
    "    OnContextCondition(\n",
    "        target=AgentTarget(advanced_troubleshooting_agent),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${repeat_issue} == True\")\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# For first-time issues, revert to user\n",
    "# computer_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "\n",
    "# Similarly for smartphone agent\n",
    "smartphone_agent.handoffs.add_context_conditions([\n",
    "    OnContextCondition(\n",
    "        target=AgentTarget(advanced_troubleshooting_agent),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${repeat_issue} == True\")\n",
    "        )\n",
    "    )\n",
    "])\n",
    "# smartphone_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "\n",
    "# Configure handoffs for advanced troubleshooting agent\n",
    "advanced_troubleshooting_agent.handoffs.set_after_work(RevertToUserTarget())\n",
    "\n",
    "general_agent.handoffs.set_after_work(RevertToUserTarget())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user agent\n",
    "user = ConversableAgent(name=\"user\", human_input_mode=\"ALWAYS\")\n",
    "\n",
    "# Set up the conversation pattern\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=triage_agent,\n",
    "    agents=[\n",
    "        triage_agent,\n",
    "        tech_agent,\n",
    "        computer_agent,\n",
    "        smartphone_agent,\n",
    "        advanced_troubleshooting_agent,\n",
    "        general_agent\n",
    "    ],\n",
    "    user_agent=user,\n",
    "    context_variables=support_context,\n",
    "    group_manager_args = {\"llm_config\": llm_config},\n",
    ")\n",
    "\n",
    "# Run the chat\n",
    "result, final_context, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"My laptop keeps shutting down randomly. Can you help?\",\n",
    "    max_rounds=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4043d8",
   "metadata": {},
   "source": [
    "example output:\n",
    "```\n",
    "user (to chat_manager):\n",
    "\n",
    "My laptop keeps shutting down randomly. Can you help?\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: triage_agent\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "triage_agent (to chat_manager):\n",
    "\n",
    "This sounds like a technical query. I will now classify the query for appropriate routing.\n",
    "\n",
    "**Classifying query...**\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: tech_agent\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "tech_agent (to chat_manager):\n",
    "\n",
    "***** Suggested tool call (call_tGgsphmvaldi4NpISolDMuqf): transfer_to_computer_agent_1 *****\n",
    "Arguments:\n",
    "{}\n",
    "*********************************************************************************************\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: _Group_Tool_Executor\n",
    "\n",
    ">>>>>>>> EXECUTING FUNCTION transfer_to_computer_agent_1...\n",
    "Call ID: call_tGgsphmvaldi4NpISolDMuqf\n",
    "Input arguments: {}\n",
    "_Group_Tool_Executor (to chat_manager):\n",
    "\n",
    "***** Response from calling tool (call_tGgsphmvaldi4NpISolDMuqf) *****\n",
    "Transfer to computer_agent\n",
    "**********************************************************************\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: computer_agent\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "computer_agent (to chat_manager):\n",
    "\n",
    "It sounds like your laptop may be having a hardware or overheating issue. Here are a few steps you can take to troubleshoot the problem:\n",
    "\n",
    "1. **Check for Overheating**: Ensure that the vents of the laptop are not blocked. Use compressed air to clear out dust from the fans and vents.\n",
    "\n",
    "2. **Battery Health**: If your laptop has a removable battery, try running it without the battery (only using the power adapter) to see if it still shuts down. If it doesn’t, you may need to replace the battery.\n",
    "\n",
    "3. **Power Supply Issues**: Make sure that your power adapter is working properly. Try using a different power adapter that is compatible with your laptop if you have one available.\n",
    "\n",
    "4. **Update Drivers and BIOS**: Make sure that all your drivers (especially the chipset and graphics drivers) are up to date, along with the BIOS.\n",
    "\n",
    "5. **Run Hardware Diagnostics**: Many laptops come with built-in hardware diagnostics. Check your manufacturer’s website for instructions on how to access and run these tests.\n",
    "\n",
    "If these steps don’t resolve the issue, let me know!\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: user\n",
    "\n",
    "Replying as user. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: I tried all your suggestions and none of them fixed my issue\n",
    "user (to chat_manager):\n",
    "\n",
    "I tried all your suggestions and none of them fixed my issue\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: computer_agent\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "computer_agent (to chat_manager):\n",
    "\n",
    "It sounds like we need to dive a bit deeper into this issue. I will escalate this to advanced troubleshooting for you. Please hold on while I check for repeat issues.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: advanced_troubleshooting_agent\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "advanced_troubleshooting_agent (to chat_manager):\n",
    "\n",
    "Thank you for your patience. Since the initial troubleshooting steps didn’t resolve the problem, we can look at more advanced diagnostics to get to the root cause of your laptop shutting down randomly.\n",
    "\n",
    "1. **Event Viewer Analysis**:\n",
    "   - Open Event Viewer by typing “eventvwr.msc” into the Run dialog (Win + R).\n",
    "   - Look for critical errors under \"Windows Logs\" > \"System\". Pay particular attention to events marked with a red exclamation mark that occurred around the time of the shutdown. This might provide insights into whether it’s a hardware failure, kernel panics, or software corruption.\n",
    "\n",
    "2. **Temperature Monitoring**:\n",
    "   - Use software tools like HWMonitor, Core Temp, or MSI Afterburner to monitor your CPU and GPU temperatures in real time.\n",
    "   - If temperatures are significantly above the normal operating range (typically above 80°C under load), then overheating could still be a primary factor, possibly indicating that thermal paste may need to be reapplied on the CPU/GPU or that the cooling system requires professional cleaning or repair.\n",
    "\n",
    "3. **Memory Test**:\n",
    "   - Run Windows Memory Diagnostic (search for \"Windows Memory Diagnostic\" in the start menu) or use a more comprehensive tool like MemTest86 to rule out RAM issues. Let it run for multiple passes to ensure thorough testing.\n",
    "\n",
    "4. **Disk Integrity Check**:\n",
    "   - Run “chkdsk /f /r” in the Command Prompt (as Administrator) to check for and repair any disk errors. Note that this might require a restart.\n",
    "\n",
    "5. **Check for Malware or Corrupted System Files**:\n",
    "   - Run a full system scan using your antivirus software or use Windows Defender. Also, run “sfc /scannow” from an elevated Command Prompt to check for and repair corrupted system files.\n",
    "\n",
    "6. **Power and Sleep Settings**:\n",
    "   - Check the power settings (Control Panel > Power Options) to ensure there are no custom settings that might be causing the laptop to shut down. Sometimes a faulty power plan can lead to unexpected behavior.\n",
    "\n",
    "7. **Physical Hardware Checks**:\n",
    "   - If you feel comfortable, open the laptop (if it's user-serviceable) to check for any loose connections, particularly around the power supply, motherboard, and battery. Check for any signs of damage or burnt components.\n",
    "\n",
    "8. **BIOS Settings**:\n",
    "   - Sometimes, certain settings in the BIOS related to power management can cause instability. Resetting the BIOS to default settings or updating to the latest version can sometimes help.\n",
    "\n",
    "If, after these advanced diagnostics, the issue persists, we may need to explore more severe hardware issues, such as problems with the motherboard or a failing power supply. If you’re comfortable with hardware repairs, consider the possibility of testing with known good components if available. Otherwise, professional service might be necessary. Let me know how it goes, and we can take further steps based on your findings.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: user\n",
    "\n",
    "Replying as user. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n",
    "\n",
    ">>>>>>>> TERMINATING RUN (e1d28d36-15f8-4e17-b021-c324cf82062a): User requested to end the conversation\n",
    "\n",
    ">>>>>>>> TERMINATING RUN (e9063a2a-4c36-443e-b938-02eee57e09f9): No reply generated\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76322f1e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
